% LaTeX file for Chapter 02
<<'preamble02',include=FALSE>>=
library(knitr) 
opts_chunk$set( 
    fig.path='figure/ch02_fig',    
    self.contained=FALSE,
    cache=!FALSE
) 
@


<<echo=FALSE>>=
library(knitr) 
opts_chunk$set( 
    fig.path='figure/ch02_fig',    
    self.contained=FALSE,
    cache=TRUE
) 
@



<<echo=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(fig.path='figure/ch02_fig',
               echo=TRUE, message=FALSE,
               fig.width=7, fig.height=7,  
               out.width='\\textwidth-3cm',
               message=FALSE, fig.align='center',
               background="gray98", tidy=FALSE, #tidy.opts=list(width.cutoff=60),
               cache=TRUE
) 
knitr::opts_chunk$set(highlight = FALSE)
options(width=74)
@ 

\chapter{Methodology} 

\section{Definitions}

The \textbf{Target Population} is a specific group within the broader population, defined by attributes relevant to the research question. This group is focused on criteria that match the study's goals \citep{willie2024population}. Defining the target population allows researchers to refine their objectives and recruitment methods to align with the study's aims.


The \textbf{Eligibility} criteria are the specific requirements that individuals must meet to participate in a study. Eligible patients will be selected from the target population. Inclusion criteria specify the conditions that allow individuals to participate in the trial, particularly focusing on the medical condition of interest. Any other factors that limit eligibility are classified as exclusion criteria \citep{van2007eligibility}, conditions or circumstances that disqualify potential participants \citep{food2018evaluating}.


In clinical trials, \textbf{Enrollment} refers to the formal process of registering participants into a study after they have met all eligibility criteria and provided informed consent. This process includes verifying that each participant satisfies the inclusion and exclusion criteria outlined in the study protocol \citep{NIH2021}. It is important to distinguish between recruitment and enrollment. Recruitment involves identifying and inviting potential participants to join the study, whereas enrollment occurs after these individuals have been screened, consented, and officially registered into the trial \citep{frank2004current}. 

Once enrolled, participants are assigned to specific treatment groups or interventions as defined by the study design. The most common practice is \textbf{Randomization}. In clinical research, randomization is the process of assigning participants to different treatment groups using chance methods, such as random number generators or coin flips \citep{lim2019randomization}. Randomized controlled trials (RCTs) are considered the most effective method for preventing bias in the evaluation of new interventions, drugs, or devices. \citep{van2007eligibility}.


In clinical research, \textbf{Statistical Analysis} involves applying statistical methods to collect, summarize, interpret, and present data derived from clinical studies. This process is essential for evaluating the safety, efficacy, and overall outcomes of medical interventions, ensuring that conclusions drawn are both reliable and valid \citep{panos2023statistical}. Not all participants who are randomized may be included in the final statistical analysis due to protocol deviations of patients not adhering to the protocol \citep{rehman2020exclusion}, missing data \citep{shih2002problems} or loss-to-follow-up, some participants may become unreachable or withdraw consent during the study, resulting in missing outcome data \citep{nuesch2009effects}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{fig_2_1_a.png}
  \caption{Patient leakage at each stage of a clinical study \citep{piantadosi2022principles, whelan2018high, bogin2022lasagna}.}
  \label{fig:2_1_a}
\end{figure}

The number of patients decreases at each stage of a clinical study, from defining the target population to final statistical analysis, see Figure \ref{fig:2_1_b}. This process is known as patient leakage \citep{desai2014preventing}, alternative terms are attrition or retention. Eligibility criteria narrow down participants, and enrollment further reduces numbers as only those meeting strict criteria are registered. Randomization assigns individuals to treatment groups, but some may later be excluded due to protocol deviations, missing data, or loss to follow-up. 

The general notion of \textbf{Recruitment} in this Master Thesis refers to the number of patients (Counts) at the Eligibility, or Enrollment, or Randomization, or Statistical Analysis stage in Figure \ref{fig:2_1_a}. We define \textbf{Accrual} as cumulative recruitment.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{fig_2_1_b.png}
  \caption{Visual representation of patient leakage at each stage of a clinical study \citep{piantadosi2022principles, whelan2018high, bogin2022lasagna}.}
  \label{fig:2_1_b}
\end{figure}

\section{Uncertainty and models for counts}

There are two types of uncertainty, aleatory and epistemic \citep{ohagan2006}. The \textbf{Aleatory Uncertainty} reflects randomness that is inherent, irreducible and unpredictable in nature. \textbf{Epistemic Uncertainty} arises primarily from limited or imperfect knowledge about the parameters of a statistical model and can reflect fluctuations of the parameter, see Figure \ref{fig:2_1_c}. Obtaining more or better information about the parameter typically reduces the epistemic uncertainty. 

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{illustration_uncertainty.png}
  \caption{Visualization of two types of uncertainty \citep{yang2023explainable}.}
  \label{fig:2_1_c}
\end{figure}

Let us denote

\begin{itemize}
\item $T=time$
\item $C=counts$
\item $\lambda=\frac{C}{T}$
\end{itemize}

We define the rate ($\lambda=\frac{C}{T}$) at which eligible patients are entered onto a clinical trial, measured as persons per unit of time as \textbf{Accrual Rate}. Where \textbf{rate} is understood as a ratio in which the numerator and denominator are incremental differences \citep{piantadosi2024clinical}. 

\begin{table}[h!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{cccccc}
 \textbf{Methods} & \textbf{Counts} & \textbf{Expectation} & \textbf{Variance} & \textbf{Aleatory} & \textbf{Epistemic} \\
\hline
\hline
Expectation & $C(t) = \lambda  t$ & $\lambda  t$ & 0 & No & No \\
Poisson & $C(t) \sim \textrm{Po} (\lambda  t)$ & $\lambda  t$ & $\lambda  t$ & Yes & No \\
Negative Binomial & $C(t) \sim \textrm{Po} (\Lambda  t)$; $\Lambda \sim \textrm{G}(\alpha,\beta)$ & $\frac{\alpha}{\beta}$ & $\frac{\alpha(\beta+1)}{\beta^2}$ & Yes & Yes \\
\end{tabular}
}
\caption{Moments and aleatory and epistemic uncertainty in accrual covered by different models for counts.}
\label{tab:count_modeling}
\end{table}

\section{Counts: Model based on Expectations}
\label{sec:expect}

If we fix the duration of a study at time $T$ and we expect that we collect $C$ patients until $T$, we deterministically predict the recruitment rate (without taking into consideration any uncertainty) to be $\hat{\lambda}=\frac{C}{T}$ . 


\subsection{Expected recruitment in one unit of time}
$C = \textrm{E}C = \textrm{E}\lambda = \lambda$
$\textrm{Var}(C) = \textrm{Var}(\lambda) = 0$

\subsection{Expected accrual at time point $t$}
$C(t) = \textrm{E}(\underbrace{C+\ldots+C}_{t times}) = \textrm{E}(\lambda t) = \lambda t$
$\textrm{Var}(C(t)) = \textrm{Var}(\underbrace{C+\ldots+C}_{t times}) = t \textrm{Var}(\lambda) = 0$

Both the expected accrual and its zero-variance are recorded in Table \ref{tab:count_modeling}
and visualized in Figure \ref{fig:2_2} and Figure \ref{fig:2_5}.



\section{Counts: Model based on Poisson Process}

The Poisson distribution $C\sim \rm{Po} (\lambda)$ allows us to explain the recruitment of patients. It is a discrete variable that expresses the probability of a given number of events (in our case, patient recruitment) occurring in a fixed unit interval of time. We assume that these events occur with a known constant rate $\lambda$ and are independent of each other.

\begin{align*}
\textrm{P}[C=&c] = \frac{\lambda^c}{c!}e^{-\lambda} \\
&c = 0,1,2,\ldots
\end{align*}


One important property from the Poisson distribution is that it is infinitely divisible \citep{held2014applied}. If $X_i\sim \textrm{Po} (\lambda_i)$ for $i=1,\ldots, n$ are independent, then, $\sum_{i=1}^n X_i \sim \textrm{Po} \Big( \sum_{i=1}^n \lambda_i \Big)$.

\subsection{Recruitment in one unit of time}

The recruitment of patients in one unit of time follows $C\sim \textrm{Po} (\lambda)$ and the expectation and variance are:

\begin{align*}
\textrm{E}C & = \lambda \\
\textrm{Var}(C) & = \lambda
\end{align*}

\subsection{Accrual at time point $t$}
At time point $t$, the accrual follows $C\sim \textrm{Po} (\lambda t)$. Using the infinitely divisible property from the Poisson applicable to independent random variables, $\underbrace{\textrm{Po} (\lambda) +\cdots +\textrm{Po} (\lambda)}_{t \ \text{times}} = \textrm{Po} (\lambda t)$. We assume that the recruitment of patients at a given time point is independent from another. As we can see in Table \ref{tab:count_modeling}, the expectation and variance are the following:

\begin{align*}
\textrm{E}C(t) & = \lambda t \\
\textrm{Var}(C(t)) & = \lambda t
\end{align*}

For example, if we assume $\lambda = 0.591$ per day and $T=550$, we can show the accrual of 100 different studies in Figure \ref{fig:2_2} and the histogram at $t=550$ days. The exact distribution at $T=550$ is provided in Figure \ref{fig:2_3} and the Cummulative Distribution Function (CDF) in Figure \ref{fig:2_4}. The uncertainty bands based on the theoretical quantiles are displayed in Figure \ref{fig:2_5}.

\begin{figure}
<<echo=FALSE>>=
# 1000 PATHS
# Set parameters
set.seed(2025)

n <- 100
t <- seq(1, 550, 1)
lambda <- 0.591

# Generate cumulative Poisson paths
cval_cum_matrix <- matrix(NA, nrow = n, ncol = length(t))

for (i in 1:n) {
	cval <- rpois(length(t), lambda)  
	cval_cum_matrix[i, ] <- cumsum(cval)  
}

# Extract final counts for histogram
final_counts <- cval_cum_matrix[, length(t)]

# Reset graphics device to avoid layout issues
# if (dev.cur() > 1) dev.off()

# Set up layout: Histogram (small, upper right) + Main plot
layout(matrix(c(1, 2), ncol = 2), widths = c(3, 1), heights = c(4, 1))  

# Plot the main accrual time series
par(mar = c(4.1, 4.1, 2.1, 2.1))  # Restore normal margins
plot(t,  cval_cum_matrix[1,], 
		 type="n", 
		 main = "Accrual of 100 studies", 
		 xlab = "Time", 
		 ylab = "Count")

for(i in 1:n){
	lines(t,  cval_cum_matrix[i,], col = "lightgray")
}

# Add reference lines
lines(t, lambda*t)
lines(t, qpois(p = 0.975, lambda*t), lty = 2, lwd = 2, col = "red")
lines(t, qpois(p = 0.025, lambda*t), lty = 2, lwd = 2, col = "red")

legend("topleft",
			 legend = c("2.5th - 97.5th Percentile [95%]",
			 					 "Expected Accrual"),
			 col = c("red", "black"),
			 lty = c(2, 1),
			 lwd = c(2,2),
			 bg = "white",
			 cex = 0.7)  

# Plot histogram in the smaller upper right section
par(mar = c(28, 0.01, 2.1, 2.1))  # Minimize margins
hist_bins <- seq(min(final_counts), max(final_counts), length.out = 15)
hist_data <- hist(final_counts, breaks = hist_bins, plot = FALSE)

barplot(hist_data$counts, horiz = TRUE, space = 0, col = "gray", 
				axes = FALSE, xlab = "", ylab = "")
@   
  \caption{Poisson-distributed counts with $\lambda = 0.591$ per day and uncertainty range. The black line represents the point estimate of the expected accrual from section \ref{sec:expect}, while the red dashed lines indicate Poisson's 95\% aleatory uncertainty. The histogram illustrates the distribution of observed counts in 100 studies at time $t = 550$ days \citep{spiegelhalter2011visualizing, pkgacc}.}
  \label{fig:2_2}
\end{figure}


\begin{figure}
<<echo=FALSE>>=
bar_positions <- barplot(dpois(200:500, lambda*550), 
												 main = "Probability Mass Function (PMF)", 
												 xlab = "Counts", 
												 xaxt = "n")  

axis(1, at = seq(1, length(200:500), by = 50), labels = seq(200, 500, by = 50))  
@   
  \caption{Probability Mass Function (PMF) of Poisson-distributed counts: This bar plot represents the probability mass function (PMF) of counts ranging from 200 to 500, using a Poisson distribution $\textrm{Po}(\lambda t)$ with a rate parameter $\lambda = 0.591$ per day at time $t = 550$ days.}
  \label{fig:2_3}
\end{figure}

\begin{figure}
<<echo=FALSE>>=
probdist <- dpois(200:500, lambda*550)
cdf <- cumsum(probdist)
cdf_positions <- barplot(cdf, 
												 main = "Cummulative distribution", 
												 xlab = "Counts", 
												 xaxt = "n")
axis(1, at = seq(1, length(200:500), by = 50), labels = seq(200, 500, by = 50))  
@   
  \caption{Cumulative Distribution Function (CDF) of Poisson-distributed counts: The bar plot illustrates the cumulative probability distribution for counts within the range of 200 to 500, using a Poisson $\textrm{Po}(\lambda t)$ distribution with a rate parameter $\lambda = 0.591$ per day at time $t=550$ days.}
  \label{fig:2_4}
\end{figure}


\begin{figure}
<<echo=FALSE>>=

# Compute Poisson quantiles over time
q_975_line <- qpois(0.975, lambda * t)
q_900_line <- qpois(0.900, lambda * t)
q_750_line <- qpois(0.75, lambda * t)
q_250_line <- qpois(0.25, lambda * t)
q_100_line <- qpois(0.1, lambda * t)
q_025_line <- qpois(0.025, lambda * t)

# Define x and y axis limits
x_limits <- range(t)
y_limits <- range(cval_cum_matrix)  # Ensures all quantiles fit

# Create the plot
par(mar = c(4.1, 4.1, 2.1, 2.1))
plot(NA, NA, xlim = x_limits, ylim = y_limits, xlab = "Time", ylab = "Count",
		 main = "Quantiles")

# Fill the area with a green gradient
polygon(c(t, rev(t)), c(q_975_line, rev(q_900_line)), col = rgb(144/255, 238/255, 144/255, 0.4), border = NA) # Light Green
polygon(c(t, rev(t)), c(q_900_line, rev(q_750_line)), col = rgb(50/255, 205/255, 50/255, 0.4), border = NA)  # Lime Green
polygon(c(t, rev(t)), c(q_750_line, rev(q_250_line)), col = rgb(0/255, 100/255, 0/255, 0.4), border = NA)    # Dark Green
polygon(c(t, rev(t)), c(q_250_line, rev(q_100_line)), col = rgb(50/255, 205/255, 50/255, 0.4), border = NA)  # Lime Green
polygon(c(t, rev(t)), c(q_100_line, rev(q_025_line)), col = rgb(144/255, 238/255, 144/255, 0.4), border = NA) # Light Green

# Add the mean trend line
lines(t, lambda * t, col = "black", lwd = 2)  

# Legend
legend("topleft",
			 legend = c("2.5th - 97.5th Percentile [95%]", 
			 					 "10th - 90th Percentile     [80%]", 
			 					 "25th - 75th Percentile     [50%]", 
			 					 "Expected Accrual"),
			 col = c(rgb(144/255, 238/255, 144/255, 0.4), rgb(50/255, 205/255, 50/255, 0.4), rgb(0/255, 100/255, 0/255, 0.4), "black"),
			 pch = c(15, 15, 15, NA), lty = c(NA, NA, NA, 1), lwd = c(NA, NA, NA, 2),
			 bg = "white",
			 cex = 0.7)
@   
  \caption{Predicted uncertainty bands for Poisson process with $\lambda = 0.591$ per day. The black line represents the expected accrual, while the green shaded regions indicate aleatory uncertainty: the dark green band spans the interquantile range (25th - 75th percentiles), the lighter green band cover the 10th - 90th percentile range and the light green the 2.5th - 97.5th percentile range \citep{spiegelhalter2011visualizing}.}
  \label{fig:2_5}
\end{figure}
\newpage
\section{Counts: Negative Binomial model derived from Poisson-Gamma model}

The Negative Binomial $X\sim\textrm{NBin}(r,\pi)$ models the number of 
\textit{trials} in a sequence of independent and identically distributed Bernouillis before $r$ \textit{successes} occur. Instead of representing the number of successes in $n$ trials like a $Y\sim \textrm{Bin} (n, \pi)$, with the Negative Binomial we are looking at how many trials will it take to obtain $r$ successes.

With respect to the parameters, $r>0$ represents the number of successes until 
the experiment is stopped. The success probability in each experiment is 
represented by $\pi\in[0,1]$.  In R the functions \texttt{nbinom(..., size = r, prob = $\pi$)} relate to the random variable $X-r$, the number of successes (as opposed to the number of trials) until $r$ successes have been achieved \citep{held2014applied}. 

\begin{align*}
EX & = \frac{r(1-\pi)}{\pi}\\
Var(X) & = \frac{r(1-\pi)}{\pi^2}
\end{align*}


\subsection{Recruitment in one unit of time}
Let $C|\Lambda \sim \textrm{Po}(\Lambda)$ and $\Lambda \sim \textrm{G}(\alpha,\beta)$
\begin{align*}
p(c)&=\int^\infty_0 p(c|\lambda) p(\lambda) d\lambda\\
&=\int^\infty_0 \frac{\lambda^c\exp(-\lambda)}{c!}\Bigg[\lambda^{\alpha-1}\exp(-\beta\lambda)\frac{\beta^\alpha}{\Gamma(\alpha)}\Bigg]d\lambda\\
&=\frac{\beta^\alpha}{c!\Gamma(\alpha)}\int^\infty_0 \lambda^{\alpha+c-1}\exp(-\lambda)\exp(-\lambda\beta)d\lambda\\
&=\frac{\beta^\alpha\Gamma(\alpha+c)}{c!\Gamma(\alpha) (\beta+1)^{\alpha+c}}\underbrace{\int^\infty_0 \frac{(\beta+1)^{\alpha+c}}{\Gamma(\alpha+c)} \lambda^{\alpha+c-1}\exp(-(\beta+1)\lambda)d\lambda}_{=1}\\
&=\beta^\alpha\binom{\alpha+c-1}{\alpha-1}\Bigg (\frac{1}{\beta+1}\Bigg)^{\alpha+c}\\
&=\binom{\alpha+c-1}{\alpha-1}\Bigg (\frac{1}{\beta+1}\Bigg)^{c} \Bigg(\frac{\beta}{\beta+1}\Bigg)^{\alpha}
\end{align*}
Thus, $C|\Lambda\sim \textrm{NBin} \Bigg(\alpha, \frac{\beta}{\beta+1}\Bigg)$


\newpage

Using the expressions of iterated expectation and variance \citep{held2014applied} and the expectation and variance from the respective random variables $C|\Lambda \sim \textrm{Po}(\Lambda)$ and $\Lambda \sim \textrm{G}(\alpha,\beta)$, we have that:


\begin{align*}
\textrm{E}C &= \textrm{E}_{\Lambda}[\textrm{E}_{C} (C|\Lambda)] = \textrm{E}_{\Lambda}[\Lambda] = \alpha/\beta
\end{align*}

\begin{align*}
\textrm{Var}(C) &= \textrm{Var}_{\Lambda}[\textrm{E}_{C} (C|\Lambda)] + \textrm{E}_{\Lambda}[\textrm{Var}_C(C|\Lambda)]\\
&=\textrm{Var}_{\Lambda}[\Lambda] + \textrm{E}_{\Lambda}[\Lambda] \\
&=\alpha/\beta^2 + \alpha/\beta = \frac{\alpha(\beta+1)}{\beta^2}
\end{align*}

% 
% \begin{align*}
% Mean &= \frac{\alpha\bigg(1-\frac{\beta}{\beta+1}\bigg)}{\frac{\beta}{\beta+1}}\\
% &= \frac{\alpha\bigg (\frac{1}{\beta+1}\bigg)}{\frac{\beta}{\beta+1}}\\
% &= \frac{\alpha(\beta+1)}{\beta(\beta+1)}\\
% &= \frac{\alpha}{\beta}
% \end{align*}
% 
% \begin{align*}
% Variance &= \frac{\alpha\bigg(1-\frac{\beta}{\beta+1}\bigg)}{\bigg(\frac{\beta}{\beta+1}\bigg)^2}\\
% &= \frac{\alpha\bigg (\frac{1}{\beta+1}\bigg)}{\bigg(\frac{\beta}{\beta+1}\bigg)^2}\\
% &= \frac{\alpha(\beta+1)^2}{\beta^2(\beta+1)}\\
% &= \frac{\alpha(\beta+1)}{\beta^2}
% \end{align*}


\subsection{Accrual at time point t}
Let $C|\Lambda \sim \textrm{Po}(\Lambda t)$ and $\Lambda \sim \textrm{G}(\alpha,\beta)$


\begin{figure}
<<echo=FALSE>>=
plot(200:500, dpois(200:500, lambda*550), 
		 type = "l",
		 main = "Probability Mass Function", 
		 xlab = "Counts", 
		 ylab = "",
		 xaxt = "n")

alpha = 324
beta = 1.5 * 365

lines(200:500, dnbinom(200:500, size = 324, mu = lambda*550), col = 2)

legend("topleft",
			 legend = c("Poisson",
			 					 "Negative Binomial"),
			 col = c("black", "red"),
			 lty = c(1, 1),
			 bg = "white",
			 cex = 0.7)  
@   
  \caption{Comparison of Probability Mass Function (PMF) between Poisson distribution with $\lambda = 0.591$ and Negative Binomial with $\alpha = 324$ and $\mu = 0.591$.}
  \label{fig:2_6}
\end{figure}



\begin{figure}
<<echo=FALSE>>=
plot(200:500, ppois(200:500, lambda*550), 
		 type = "l",
		 main = "Cummulative Distribution Function", 
		 xlab = "Counts", 
		 ylab = "",
		 xaxt = "n")

alpha = 324
beta = 1.5 * 365

lines(200:500, pnbinom(200:500, size = 324, mu = lambda*550), col = 2)

legend("topleft",
			 legend = c("Poisson",
			 					 "Negative Binomial"),
			 col = c("black", "red"),
			 lty = c(1, 1),
			 bg = "white",
			 cex = 0.7)
@   
  \caption{Comparison of Cummulative Distribution Function (CDF) between Poisson distribution with $\lambda = 0.591$ and Negative Binomial with $\alpha = 324$ and $\mu = 0.591$.}
  \label{fig:2_7}
\end{figure}



\begin{figure}
<<echo=FALSE>>=
alpha = 324
beta = 1.5 * 365

plot(200:500, dgamma(200:500, shape = alpha, rate = beta), 
		 type = "l",
		 main = "Probability Density Function", 
		 xlab = "Counts", 
		 ylab = "",
		 xaxt = "n")
@   
  \caption{Gamma density function with $\alpha = 324$ and $\beta = 1.5 \cdot 365$.}
  \label{fig:2_8}
\end{figure}



\section{Important questions when forecasting recruitment at the design-stage of a study}

By normal approximation to the Poisson distribution $C\sim \textrm{N}(\mu=\lambda T, \sigma^2=(\lambda T)^2)$, we know that the probability of recruiting the desired $N$ participants is 0.5. Which means that the study has 50\% chance of obtaining the desired sample size in the suggested $T$ \citep{carter2004application}. We would also be assuming that the recruitment rate is constant over time.

In fact, we do not need normal approximation to see this...

This raises two questions which will be answered throughout this Master Thesis:
\begin{enumerate}
\item \textbf{Rate:} If $T$ is fixed, what does the expected rate $\lambda$ need to be to achieve a certain certainty of enrolling the total sample size $N$ within the time frame $T$?
\item \textbf{Time:} Given a certain rate $\lambda$, how long should the recruitment period $T$ be planned to give a confidence above 50\% of recruiting the total sample size $N$? In Machine Learning, this confidence is aimed at 80\%. In \cite{carter2004application}, at 90\%.
\end{enumerate}
