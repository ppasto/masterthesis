% LaTeX file for Chapter 03
<<'preamble03',include=FALSE>>=
library(knitr)
opts_chunk$set(
    fig.path='figure/ch03_fig', 
    self.contained=FALSE,
    cache=FALSE
) 
@

\chapter{Results}

\section{Important questions when forecasting recruitment at the design-stage of a study}

By normal approximation to the Poisson distribution $C(t)\sim \textrm{N}(\mu=\lambda t, \sigma^2=(\lambda t)^2)$, we know that the probability of recruiting the desired $N$ participants is 0.5. Which means that the study has 50\% chance of obtaining the desired sample size in the suggested $T$ \citep{carter2004application}. We would also be assuming that the recruitment rate is constant over time.

In fact, we do not need normal approximation to see this. This can be shown with the Poisson distribution itself. We only need to specify the probability above $\lambda t$, for example, 0.5. For large $\lambda$, 50\% of the distribution will be below $\lambda t$. With $\lambda < 1$ this is no longer the case. 

This raises two questions which will be answered throughout this Master Thesis:
\begin{enumerate}
\item \textbf{Rate:} If $T$ is fixed, what does the expected rate $\lambda$ need to be to achieve a certain certainty of enrolling the total sample size $N$ within the time frame $T$?
\item \textbf{Time:} Given a certain rate $\lambda$, how long should the recruitment period $T$ be planned to give a confidence above 50\% of recruiting the total sample size $N$? In Machine Learning, this confidence is aimed at 80\%. In \cite{carter2004application}, at 90\%.
\end{enumerate}

\section{Pros and cons of Monte Carlo's simulations}

Carter suggests using Monte Carlo simulations, independent and identically distributed realizations of random variables. One clear advantage is its flexibility, as we can simulate any distribution we want. However, we must consider the following when we compute MC sampling instead of exact:

\begin{itemize}
\item $M$, the number of simulations
\item Set a seed for computational reproducibility
\item Monte Carlo standard errors (MCse) of estimates based on MC simulations
\item Pseudo random numbers generated in R rely in the assumption that these pseudo random numbers are close to the true realizations of random variables \citep{held2014applied}
\end{itemize}
\section{Counts: Comparison exact vs Monte Carlo simulations}

Carter raises two important questions, enumerated in the previous section \citep{carter2004application, carter2005practical}. He suggests the use of Monte Carlo (MC) simulations for Counts. Here we investigate the accuracy of his MC simulations by comparing them with exact distributions for accrual of counts introduced in Chapter 2. 

In Figures \ref{fig:3_1} and \ref{fig:3_2}, we can see how for $n=10^5$, MC sampling converges to the theoretical approaches discussed in Chapter 2.

% otherwise, show picture of code


% 
% lalalalal
% <<echo=TRUE, eval=TRUE>>=
% set.seed(2025)
% 
% M <- 10^5
% t <- seq(1, 550, 1)
% lambda <- 0.591
% 
% # Generate cumulative Poisson paths
% cval_cum_matrix <- matrix(NA, nrow = n, ncol = length(t))
% 
% for (i in 1:M) {
% 	cval <- rpois(length(t), lambda)
% 	cval_cum_matrix[i, ] <- cumsum(cval)
% }
% 
% # Extract final counts for histogram
% final_counts <- cval_cum_matrix[, length(t)]
% @
% 

\begin{figure}
<<echo=FALSE, cache = TRUE, warning=FALSE>>=
set.seed(2025)

M <- 10^4
t <- seq(1, 550, 1)
lambda <- 0.591

# Generate cumulative Poisson paths
cval_cum_matrix <- matrix(NA, nrow = M, ncol = length(t))

for (i in 1:M) {
	cval <- rpois(length(t), lambda)  
	cval_cum_matrix[i, ] <- cumsum(cval)  
}

# Extract final counts for histogram
final_counts_p <- cval_cum_matrix[, length(t)]

x_vals <- 200:500

plot(x_vals, dpois(x_vals, lambda = lambda * 550), 
		 type = "n",
		 main = "Density Time",
		 xlab = "Day",
		 ylab = "Density")

lines(x_vals,  dpois(x_vals, lambda = lambda * 550), 
			lwd = 4,
			col = "purple")

lines(density(final_counts_p), 
			col = "blue",
			lwd = 2,
			lty = 2)

legend("topright",
			 legend = c("Theoretical Poisson", "MC sampling"),
			 col = c("purple", "blue"),
			 lwd = c(4, 2),
			 lty = c(1, 2),
			 cex = 0.7)
@
  \caption{Comparison of theoretical Probability Mass Function (PMF) of Poisson model for counts centered at $\lambda = 0.591$ for accrual at time $t=550$ and Monte Carlo (MC) sampling with $M=10^5$.}
  \label{fig:3_1}
\end{figure}



\begin{figure}
<<echo=FALSE, cache = TRUE, warning=FALSE>>=
set.seed(2025)

n <- 10^4
t <- seq(1, 550, 1)
lambda <- 0.591

alpha <- 324
beta <- 548
# Generate cumulative Poisson paths
cval_cum_matrix <- matrix(NA, nrow = n, ncol = length(t))
v_lambda <- rgamma(n, shape = alpha, rate = beta)

for (i in 1:n) {
	cval <- rpois(length(t), lambda = v_lambda[i])
	cval_cum_matrix[i, ] <- cumsum(cval)  
}

# Extract final counts for histogram
final_counts_pg <- cval_cum_matrix[, length(t)]


x_vals <- 200:500

plot(x_vals,  dnbinom(x_vals, size = 324, mu = lambda * 550), 
		 type = "n",
		 main = "Density Time",
		 xlab = "Day",
		 ylab = "Density")

lines(x_vals,  dnbinom(x_vals, size = 324, mu = lambda * 550), 
			lwd = 4,
			col = "purple")

lines(density(final_counts_pg), 
			col = "blue",
			lwd = 2,
			lty = 2)

legend("topright",
			 legend = c("Theoretical PoG", "MC sampling"),
			 col = c("purple", "blue"),
			 lwd = c(4, 2),
			 lty = c(1, 2),
			 cex = 0.7)

@
\caption{Comparison of theoretical Probability Mass Function (PMF) of Poisson-Gamma model for counts with $\alpha = 324$ and $\beta = 548$ for accrual at time $t=550$, and Monte Carlo (MC) sampling with $M=10^5$.}
\label{fig:3_2}
\end{figure}



\section{Time: Comparison exact vs Monte Carlo simulations}
% LALALA
% <<echo=TRUE, cache=TRUE, warning=FALSE>>=
% set.seed(2025)
% M <- 10^5
% Nneed <- 324
% lambda <- 0.591
% 
% timep <- rep(0, M)
% csump <- rep(0, M)
% 
% for(m in 1:M){
% 	while (csump[m] < Nneed) {
% 		csump[m] <- csump[m] + rpois(1, lambda)
% 		timep[m] <- timep[m] + 1
% 	}
% }
% @
% first check if it works!!
% add also the code chunk with negative binomial (extension of carter and bagiella)

\begin{figure}
<<echo=FALSE>>=

set.seed(2025)
M <- 10^4
Nneed <- 324
lambda <- 0.591

alpha <- 324
beta <- 548

timep <- rep(0, M)
csump <- rep(0, M)

for(m in 1:M){
	while (csump[m] < Nneed) {
		csump[m] <- csump[m] + rpois(1, lambda)
		timep[m] <- timep[m] + 1
	}
}

t_vals <- 400:700

plot(t_vals, dgamma(t_vals, shape = alpha, rate = lambda), 
		 type = "n",
		 main = "Density Time",
		 xlab = "Day",
		 ylab = "Density")

lines(t_vals, dgamma(t_vals, shape = alpha, rate = lambda), 
			lwd = 4,
			col = "purple")

lines(density(timep), 
			col = "blue",
			lwd = 2,
			lty = 2)

legend("topright",
			 legend = c("Theoretical Erlang", "MC sampling"),
			 col = c("purple", "blue"),
			 lwd = c(4, 2),
			 lty = c(1, 2),
			 cex = 0.7)


@
\caption{Comparison of theoretical Density function of Gamma model for time with parameters $\alpha = 324$ and $\beta = 548$ and Monte Carlo (MC) sampling with $M=10^5$.}
\label{fig:3_3}
\end{figure}


\begin{figure}
<<echo=FALSE, warning=FALSE, cache=TRUE>>=
set.seed(2025)
M <- 10^4
Nneed <- 324
lambda <- 0.591
alpha <- 324
beta <- 548

timepg <- rep(0, M)
csumpg <- rep(0, M)

dgammagamma <- function(t, alpha, b, c) {
	log_dens <- alpha * log(b) - lbeta(alpha, c) + (c - 1) * log(t) - (alpha + c) * log(b + t)
	dens <- exp(log_dens)
	return(dens)
}

start.time <- Sys.time()

for(m in 1:M){
	while (csumpg[m] < Nneed) {
		csumpg[m] <- csumpg[m] + rnbinom(1, size = alpha, mu = lambda*t)
		timepg[m] <- timepg[m] + 1
	}
}
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

t_vals <- 400:700

plot(t_vals, dgammagamma(t_vals, alpha = alpha, b = beta, c = Nneed), 
		 type = "n",
		 main = "Density Time",
		 xlab = "Day",
		 ylab = "Density")

lines(t_vals, dgammagamma(t_vals, alpha = alpha, b = beta, c = Nneed), 
			lwd = 4,
			col = "purple")

lines(density(timepg), 
			col = "blue",
			lwd = 2,
			lty = 2)

legend("topright",
			 legend = c("Theoretical Gg", "MC sampling"),
			 col = c("purple", "blue"),
			 lwd = c(4, 2),
			 lty = c(1, 2),
			 cex = 0.7)
@
\caption{Comparison of theoretical Density function of Gamma-Gamma model for time with parameters $\alpha = 324$ and $\beta = 548$ and Monte Carlo (MC) sampling with $M=10^5$.}
\label{fig:3_4}
\end{figure}


\begin{table}[h!]
\centering
\begin{tabular}{cccc}
Header 1 & Header 2 & Header 3 & Header 4 \\
\hline
\hline
Row 1 Col 1 & Row 1 Col 2 & Row 1 Col 3 & Row 1 Col 4 \\
Row 2 Col 1 & Row 2 Col 2 & Row 2 Col 3 & Row 2 Col 4 \\
Row 3 Col 1 & Row 3 Col 2 & Row 3 Col 3 & Row 3 Col 4 \\
Row 4 Col 1 & Row 4 Col 2 & Row 4 Col 3 & Row 4 Col 4 
\end{tabular}
\caption{Moments and aleatory and epistemic uncertainty of recruitment in one unit of time recruitment covered by different models for counts.}
\label{tab:mcse}
\end{table}




