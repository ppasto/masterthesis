% LaTeX file for Chapter 03


\chapter{Results}

\section{Important questions when forecasting recruitment at the design-stage of a study}

By normal approximation to the Poisson distribution $C(t)\sim \textrm{N}(\mu=\lambda t, \sigma^2=(\lambda t)^2)$, we know that the probability of recruiting the desired $N$ participants is 0.5. Which means that the study has 50\% chance of obtaining the desired sample size in the suggested $T$ \citep{carter2004application}. We would also be assuming that the recruitment rate is constant over time.

In fact, we do not need normal approximation to see this. This can be shown with the Poisson distribution itself. We only need to specify the probability above $\lambda t$, for example, 0.5. For large $\lambda$, 50\% of the distribution will be below $\lambda t$. With $\lambda < 1$ this is no longer the case. 

This raises two questions which will be answered throughout this Master Thesis:
\begin{enumerate}
\item \textbf{Rate:} If $T$ is fixed, what does the expected rate $\lambda$ need to be to achieve a certain certainty of enrolling the total sample size $N$ within the time frame $T$?
\item \textbf{Time:} Given a certain rate $\lambda$, how long should the recruitment period $T$ be planned to give a confidence above 50\% of recruiting the total sample size $N$? In Machine Learning, this confidence is aimed at 80\%. In \cite{carter2004application}, at 90\%.
\end{enumerate}

\section{Counts: Comparison exact vs Monte Carlo simulations}

Carter raises two important questions, enumerated in the previous section \citep{carter2004application, carter2005practical}. He suggests the use of Monte Carlo (MC) simulations for Counts. Here we investigate the accuracy of his MC simulations by comparing them with exact distributions for accrual of counts introduced in Chapter 2. 

In Figures \ref{fig:3_1} and \ref{fig:3_2}, we can see how for $n=10^5$, MC sampling converges to the theoretical approaches discussed in Chapter 2.
% 
% <<echo = TRUE, cache=TRUE>>=
% set.seed(2025)
% 
% M <- 10^5
% t <- seq(1, 550, 1)
% lambda <- 0.591
% 
% # Generate cumulative Poisson paths
% cval_cum_matrix <- matrix(NA, nrow = n, ncol = length(t))
% 
% for (i in 1:M) {
% 	cval <- rpois(length(t), lambda)
% 	cval_cum_matrix[i, ] <- cumsum(cval)
% }
% 
% # Extract final counts for histogram
% final_counts <- cval_cum_matrix[, length(t)]
% @


\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\includegraphics[width=\maxwidth]{figure/ch03_figunnamed-chunk-1-1} 
\end{knitrout}
  \caption{Comparison of theoretical Probability Mass Function (PMF) of Poisson model centered at $\lambda = 0.591$ for accrual at time $t=550$ and Monte Carlo (MC) sampling.}
  \label{fig:3_1}
\end{figure}


\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\includegraphics[width=\maxwidth]{figure/ch03_figunnamed-chunk-2-1} 
\end{knitrout}
\caption{Comparison of theoretical Probability Mass Function (PMF) of Poisson-Gamma model with $\alpha = 324$ and $\beta = 548$ for accrual at time $t=550$, and Monte Carlo (MC) sampling.}
\label{fig:3_2}
\end{figure}



\section{Time: Comparison exact vs Monte Carlo simulations}

% <<echo = TRUE, cache = TRUE>>=
% 
% set.seed(2025)
% M <- 10^5
% Nneed <- 324
% lambda <- 0.591
% 
% timep <- rep(0, M)
% csump <- rep(0, M)
% 
% for(m in 1:M){
% 	while (csump[m] < Nneed) {
% 		csump[m] <- csump[m] + rpois(1, lambda)
% 		timep[m] <- timep[m] + 1
% 	}
% }
% @

